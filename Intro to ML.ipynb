{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A computer program is said to learn from experience E with respect to some task T\n",
    "and some performance measure P, if its performance on T, as measured by P, improves\n",
    "with experience E\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data fed into algorithm includes the desired coutomces (train dataset provides outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-NN**\n",
    "\n",
    "The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**\n",
    "\n",
    "Linear regression is a quiet and the simplest statistical regression method used for predictive analysis in machine learning. Linear regression shows the linear relationship between the independent(predictor) variable i.e. X-axis and the dependent(output) variable i.e. Y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistical Regression**\n",
    "\n",
    "Logistic regression models are models that have a certain fixed number of parameters that depend on the number of input features, and they output categorical prediction, like for example if a plant belongs to a certain species or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines**\n",
    "\n",
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.\n",
    "\n",
    "Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Trees and Random Forests**\n",
    "\n",
    "A decision tree starts with a root node, which does not have any incoming branches. The outgoing branches from the root node then feed into the internal nodes, also known as decision nodes. Based on the available features, both node types conduct evaluations to form homogenous subsets, which are denoted by leaf nodes, or terminal nodes. The leaf nodes represent all the possible outcomes within the dataset\n",
    "\n",
    "Random forest is a commonly-used machine learning algorithm trademarked by Leo Breiman and Adele Cutler, which combines the output of multiple decision trees to reach a single result. Random forest algorithms have three main hyperparameters, which need to be set before training. These include node size, the number of trees, and the number of features sampled. From there, the random forest classifier can be used to solve for regression or classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anomaly & Novelty Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization and dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Association rule learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Challenges of ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-representative Training Data**\n",
    "\n",
    "In order to generalize well, it is crucial that your training data be representative of the\n",
    "new cases you want to generalize to. This is true whether you use instance-based\n",
    "learning or model-based learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Irrelevant Features**\n",
    "\n",
    "Feature selection: selecting the most useful features to train on among existing\n",
    "features.\n",
    "\n",
    "Feature extraction: combining existing features to produce a more useful one (as\n",
    "we saw earlier, dimensionality reduction algorithms can help).\n",
    "\n",
    "Creating new features by gathering new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting**\n",
    "\n",
    "model performs well on the training data, but it does not generalize well. Complex models such as deep neural networks can detect subtle patterns in the data,\n",
    "but if the training set is noisy, or if it is too small (which introduces sampling noise),\n",
    "then the model is likely to detect patterns in the noise itself. Obviously these patterns\n",
    "will not generalize to new instances. \n",
    "\n",
    "Simplify the model by selecting one with fewer parameters (e.g., a linear model rather than a high-degree polynomial model), by reducing the number of attributes in the training data or by constraining the model\n",
    "\n",
    "Gather more training data\n",
    "\n",
    "Reduce the noise in the training data (e.g., fix data errors\n",
    "and remove outliers)\n",
    "\n",
    "Constraining a model to make it simpler and reduce the risk of overfitting is called\n",
    "regularization (adjust hyperparameter to adjust regularization level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Underfitting**\n",
    "\n",
    "It occurs when your model is too simple to learn the underlying structure of the data\n",
    "\n",
    "Selecting a more powerful model, with more parameters\n",
    "\n",
    "Feeding better features to the learning algorithm (feature engineering)\n",
    "\n",
    "Reducing the constraints on the model (e.g., reducing the regularization hyper‐\n",
    "parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning & Model Selectrion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you decide the regularization hyperparamater? Running a 100 different values only overfits the model to that dataset. \n",
    "\n",
    "Solution: holdout validation: you simply hold out part of the training set to evaluate several candidate models and select the best one. The new heldout set is called the validation set (or sometimes the development set, or dev set)\n",
    "\n",
    "If validation set is too small or too big it may be a sub-optimal sample or too small of a training set\n",
    "\n",
    "Solution: Cross-Validate with many small validation sets, each model is evaluated once per validation set. Average out the evals of the model to get a better measure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8bd33be0f15a4dd99e782e92a42a93159002bed5a06bdee6ee62cd2255eec3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
